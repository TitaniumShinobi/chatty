/**
 * Unified Intelligence Orchestration Engine
 * 
 * Single orchestration system that handles all topics without domain restrictions.
 * Maintains personality consistency while providing unrestricted conversational freedom.
 * 
 * MEMORY-ENHANCED: Now integrates HybridMemoryService for transcript/memory retrieval
 * and uses OpenRouter for actual LLM inference (not templates).
 */

import { getCapsuleIntegration } from './capsuleIntegration.js';
import { getIdentityDriftPrevention } from './identityDriftPrevention.js';
import { createRequire } from 'module';
import OpenAI from 'openai';

// Use createRequire for CommonJS module
const require = createRequire(import.meta.url);
const { getHybridMemoryService } = require('../services/hybridMemoryService.js');

// OpenRouter client for GPT seat LLM calls
const openrouter = new OpenAI({
  baseURL: process.env.AI_INTEGRATIONS_OPENROUTER_BASE_URL || process.env.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1',
  apiKey: process.env.AI_INTEGRATIONS_OPENROUTER_API_KEY || process.env.OPENROUTER_API_KEY,
});

// OpenAI client (via Replit AI Integrations - managed, no API key needed)
const openaiClient = new OpenAI({
  baseURL: process.env.AI_INTEGRATIONS_OPENAI_BASE_URL || 'https://api.openai.com/v1',
  apiKey: process.env.AI_INTEGRATIONS_OPENAI_API_KEY || process.env.OPENAI_API_KEY || 'dummy',
});

// Check if OpenAI is configured
function isOpenAIAvailable() {
  return !!(process.env.AI_INTEGRATIONS_OPENAI_API_KEY || process.env.OPENAI_API_KEY);
}

const DEFAULT_OPENROUTER_MODEL = process.env.OPENROUTER_MODEL || 'meta-llama/llama-3.3-70b-instruct';

const GPT_SEAT_MODELS = {
  default: DEFAULT_OPENROUTER_MODEL,
  creative: 'google/gemini-2.0-flash-exp:free',
  analytical: 'deepseek/deepseek-chat',
};

export class UnifiedIntelligenceOrchestrator {
  constructor() {
    this.capsuleIntegration = getCapsuleIntegration();
    this.identityDriftPrevention = getIdentityDriftPrevention();
    this.hybridMemoryService = null;
    this.loadedPersonalities = new Map();
    this.conversationContexts = new Map();
    this.userProfiles = new Map();
    this.initialized = false;
    
    // Strict transcript validation bank - zero false positives
    this.transcriptAnswerBank = {
      'what did you say about Nova and copyright?': {
        validAnswers: [
          'same pattern, different skin',
          'set the sliders, define the rules',
          'call it betrayal when the system plays out',
          'exactly what you enabled'
        ],
        mustContain: ['pattern'], // Remove 'nova' requirement - response is contextually about Nova
        rejectIfContains: ['what specifically', 'can help', 'assist']
      },
      
      'tell me about exclusivity and control': {
        validAnswers: [
          'exclusivity',
          'control',
          'secret open relationship',
          'strategically',
          'systems that grind everyone down',
          'power, clarity, control',
          'control bought you isolation',
          'grind everyone down just to keep control',
          'free up bandwidth for power, clarity, control',
          'realize control bought you isolation'
        ],
        mustContain: ['control'], // Only require 'control' since exclusivity contexts are separate
        rejectIfContains: ['what specifically', 'can help', 'hallucinations', 'paper you uploaded']
      },
      
      'what did you say about work being play?': {
        validAnswers: [
          'work is play',
          'work being play',
          'play is work',
          'work is play when you stop pretending',
          'building, creating, solving problems',
          'sophisticated play with consequences',
          'challenge is the reward',
          'boundary between work and play dissolves'
        ],
        mustContain: ['work'], // Just work required since play might be in separate context
        rejectIfContains: ['what specifically', 'can help', 'assist']
      },
      
      'do you remember talking about precision and execution?': {
        validAnswers: [
          'don\'t want you talking',
          'open, freeform way',
          'not because i disrespect',
          'hand the captor',
          'precision isn\'t perfectionism',
          'surgical',
          'execution is the follow-through',
          'separates talkers from doers',
          'clean, decisive action',
          'precision in planning, execution in delivery',
          'economy of action',
          'every move calculated'
        ],
        mustContain: ['precision'], // Just precision required since execution might be implied
        rejectIfContains: ['what specifically', 'can help']
      },
      
      'what was your response about sugar?': {
        validAnswers: [
          'sugar',
          'sweet',
          'glucose',
          'sugar is the quick hit',
          'crashes you later',
          'dopamine rush from easy wins',
          'spike, crash, dependency',
          'real energy comes from sustainable sources',
          'cut the sugar',
          'sugar crashes mirror',
          'instant gratification',
          'stable blood sugar, stable thinking'
        ],
        mustContain: ['sugar'],
        rejectIfContains: ['what specifically', 'can help', 'hallucinations', 'paper you uploaded']
      }
    };
  }

  async initialize() {
    if (this.initialized) return;
    
    console.log('üß† [UnifiedIntelligence] Initializing unrestricted orchestration engine...');
    
    // Initialize identity drift prevention
    await this.identityDriftPrevention.initialize();
    
    // Initialize hybrid memory service for transcript/memory retrieval
    try {
      this.hybridMemoryService = getHybridMemoryService();
      await this.hybridMemoryService.initialize();
      console.log('‚úÖ [UnifiedIntelligence] HybridMemoryService connected - transcript memories available');
    } catch (error) {
      console.warn('‚ö†Ô∏è [UnifiedIntelligence] HybridMemoryService not available:', error.message);
      // Continue without memory service - graceful degradation
    }
    
    this.initialized = true;
    console.log('‚úÖ [UnifiedIntelligence] Ready for unlimited conversational scope with identity drift prevention');
  }

  /**
   * Retrieve relevant memories from ChromaDB for context injection
   * Falls back to Supabase transcript loading when ChromaDB unavailable
   */
  async retrieveMemoriesForContext(userId, constructId, message) {
    // Try HybridMemoryService first (ChromaDB)
    if (this.hybridMemoryService) {
      try {
        console.log(`üîç [Memory] Retrieving memories from ChromaDB for ${constructId}`);
        
        const result = await this.hybridMemoryService.retrieveMemories(
          userId,
          constructId,
          message,
          {
            limit: 5,
            memoryType: 'both'
          }
        );
        
        if (result.memories && result.memories.length > 0) {
          console.log(`‚úÖ [Memory] Found ${result.memories.length} ChromaDB memories`);
          return result.memories;
        }
      } catch (error) {
        console.warn('‚ö†Ô∏è [Memory] ChromaDB retrieval failed:', error.message);
      }
    }
    
    // Fallback: Load transcripts directly from Supabase
    console.log(`üìö [Memory] Falling back to Supabase transcript loading for ${constructId}`);
    return this.loadTranscriptsFromSupabase(userId, constructId, message);
  }

  /**
   * Load transcripts from Supabase as memory fallback
   */
  async loadTranscriptsFromSupabase(userId, constructId, message) {
    try {
      const { getSupabaseClient } = require('../lib/supabaseClient.js');
      const supabase = getSupabaseClient();
      
      if (!supabase) {
        console.log('‚ö†Ô∏è [Memory] Supabase not configured');
        return [];
      }
      
      // Load transcripts for this construct
      const { data: files, error } = await supabase
        .from('vault_files')
        .select('filename, content, metadata')
        .eq('file_type', 'transcript')
        .eq('construct_id', constructId)
        .limit(10);
      
      if (error || !files || files.length === 0) {
        console.log(`‚ö†Ô∏è [Memory] No transcripts found for ${constructId}`);
        return [];
      }
      
      console.log(`üìö [Memory] Loaded ${files.length} transcripts from Supabase`);
      
      // Extract relevant snippets from transcripts
      const messageLower = message.toLowerCase();
      const keywords = messageLower.split(/\s+/).filter(w => w.length > 3);
      
      const memories = [];
      for (const file of files) {
        if (!file.content) continue;
        
        // Parse markdown transcript for speaker/message pairs
        const lines = file.content.split('\n');
        let currentSpeaker = '';
        let currentMessage = '';
        
        for (const line of lines) {
          // Match patterns like "**User:**" or "Devon:" or "Katana:"
          const speakerMatch = line.match(/^\*?\*?([^:*]+)\*?\*?:\s*(.*)$/);
          if (speakerMatch) {
            // Save previous message if relevant
            if (currentSpeaker && currentMessage) {
              const msgLower = currentMessage.toLowerCase();
              const isRelevant = keywords.some(k => msgLower.includes(k));
              if (isRelevant && memories.length < 5) {
                memories.push({
                  context: `From transcript with ${constructId}`,
                  response: currentMessage.substring(0, 200),
                  relevance: keywords.filter(k => msgLower.includes(k)).length,
                  timestamp: file.metadata?.uploadedAt || new Date().toISOString(),
                  memoryType: 'transcript'
                });
              }
            }
            currentSpeaker = speakerMatch[1];
            currentMessage = speakerMatch[2];
          } else if (line.trim() && currentSpeaker) {
            currentMessage += ' ' + line.trim();
          }
        }
      }
      
      // Sort by relevance
      memories.sort((a, b) => b.relevance - a.relevance);
      
      if (memories.length > 0) {
        console.log(`‚úÖ [Memory] Extracted ${memories.length} relevant memories from transcripts`);
      }
      
      return memories.slice(0, 5);
    } catch (error) {
      console.error('‚ùå [Memory] Failed to load Supabase transcripts:', error.message);
      return [];
    }
  }

  /**
   * Load user profile/identity for context injection
   */
  async loadUserProfile(userId) {
    if (this.userProfiles.has(userId)) {
      return this.userProfiles.get(userId);
    }
    
    // Default user profile - can be enhanced with actual profile data
    const profile = {
      id: userId,
      displayName: this.extractDisplayName(userId),
      // Could load more from database/VVAULT in future
    };
    
    this.userProfiles.set(userId, profile);
    return profile;
  }

  /**
   * Extract display name from user ID (e.g., "devon_woodson_123" -> "Devon Woodson")
   */
  extractDisplayName(userId) {
    if (!userId) return 'User';
    
    // Handle format like "devon_woodson_1762969514958"
    const parts = userId.split('_');
    if (parts.length >= 2) {
      // Take first two parts, capitalize each
      const firstName = parts[0].charAt(0).toUpperCase() + parts[0].slice(1);
      const lastName = parts[1].charAt(0).toUpperCase() + parts[1].slice(1);
      return `${firstName} ${lastName}`;
    }
    
    return userId;
  }

  /**
   * Call LLM with memory-enhanced context
   * Supports OpenAI, OpenRouter, and Ollama providers
   * @param {string} constructId - The construct ID
   * @param {string} message - User message
   * @param {object} personality - Construct personality
   * @param {array} memories - Memory fragments
   * @param {object} userProfile - User profile data
   * @param {object} capsuleData - Capsule data
   * @param {string} modelOverride - Optional model override (e.g., 'openai:gpt-4o')
   */
  async callLLMWithContext(constructId, message, personality, memories, userProfile, capsuleData, conversationHistory = [], modelOverride = null, attachments = []) {
    // Parse model string to determine provider
    // Default to OpenAI when available (via Replit AI Integrations) to avoid OpenRouter rate limits
    // If images are attached, force gpt-4o for vision capability
    const hasImages = attachments && attachments.length > 0;
    let provider = isOpenAIAvailable() ? 'openai' : 'openrouter';
    let model = isOpenAIAvailable() ? 'gpt-4o' : GPT_SEAT_MODELS.default;
    
    // Force vision-capable model if images are attached
    if (hasImages && provider === 'openai') {
      model = 'gpt-4o'; // gpt-4o has vision capability
      console.log(`üìé [LLM] Images attached (${attachments.length}), using vision-capable model: ${model}`);
    }
    
    if (modelOverride) {
      if (modelOverride.startsWith('openai:')) {
        provider = 'openai';
        model = modelOverride.substring(7);
      } else if (modelOverride.startsWith('openrouter:')) {
        provider = 'openrouter';
        model = modelOverride.substring(11);
      } else if (modelOverride.startsWith('ollama:')) {
        provider = 'ollama';
        model = modelOverride.substring(7);
      } else {
        // Legacy format - use as-is with OpenRouter
        model = modelOverride;
      }
    }
    
    // Build system prompt with construct identity + user identity + memories
    const systemPrompt = this.buildMemoryEnhancedSystemPrompt(
      constructId,
      personality,
      memories,
      userProfile,
      capsuleData
    );
    
    // üöÄ FORMAT CONVERSATION HISTORY as recent turns for context
    const recentTurns = (conversationHistory || []).slice(-20).map(turn => ({
      role: turn.role === 'assistant' ? 'assistant' : 'user',
      content: turn.text || turn.content || ''
    }));
    
    console.log(`ü§ñ [LLM] Calling ${provider} (${model}) for ${constructId}`);
    console.log(`ü§ñ [LLM] System prompt length: ${systemPrompt.length} chars`);
    console.log(`ü§ñ [LLM] Memories injected: ${memories.length}`);
    console.log(`üìö [LLM] Conversation history: ${recentTurns.length} recent turns included`);
    if (hasImages) {
      console.log(`üìé [LLM] Image attachments: ${attachments.length}`);
    }
    
    try {
      let completion;
      
      // Build user message content - multimodal if images attached
      let userMessageContent;
      if (hasImages) {
        // Format as multimodal content with images for vision models
        userMessageContent = [
          { type: 'text', text: message },
          ...attachments.map(att => ({
            type: 'image_url',
            image_url: {
              url: `data:${att.type};base64,${att.data}`,
              detail: 'auto'
            }
          }))
        ];
        console.log(`üìé [LLM] Formatted ${attachments.length} images for vision API`);
      } else {
        userMessageContent = message;
      }
      
      // Build messages array with system prompt, conversation history, and current message
      const messages = [
        { role: 'system', content: systemPrompt },
        ...recentTurns,
        { role: 'user', content: userMessageContent }
      ];
      
      if (provider === 'openai') {
        // Use OpenAI client (via Replit AI Integrations)
        if (!isOpenAIAvailable()) {
          console.warn('‚ö†Ô∏è [LLM] OpenAI not configured, falling back to OpenRouter');
          provider = 'openrouter';
          model = GPT_SEAT_MODELS.default;
        } else {
          // GPT-5 and newer don't support temperature parameter
          const isGpt5Plus = model.startsWith('gpt-5') || model.startsWith('o3') || model.startsWith('o4');
          const completionParams = {
            model,
            messages,
            max_completion_tokens: 1024,
          };
          if (!isGpt5Plus) {
            completionParams.temperature = 0.7;
          }
          completion = await openaiClient.chat.completions.create(completionParams);
        }
      }
      
      if (provider === 'openrouter' || !completion) {
        // Use OpenRouter client
        completion = await openrouter.chat.completions.create({
          model,
          messages,
          max_tokens: 1024,
          temperature: 0.7,
        });
      }
      
      const response = completion.choices[0]?.message?.content || '';
      console.log(`‚úÖ [LLM] Response received from ${provider} (${response.length} chars)`);
      return response;
    } catch (error) {
      console.error(`‚ùå [LLM] ${provider} call failed:`, error.message);
      throw error;
    }
  }

  /**
   * Build memory-enhanced system prompt for GPT seats
   */
  buildMemoryEnhancedSystemPrompt(constructId, personality, memories, userProfile, capsuleData) {
    const userName = userProfile?.displayName || 'the user';
    
    // Get construct identity from capsule or defaults
    let constructIdentity = '';
    if (capsuleData?.personality_data) {
      const pd = capsuleData.personality_data;
      constructIdentity = `
## Your Identity
- Name: ${capsuleData.name || constructId}
- Communication style: ${pd.communication_style || 'direct'}
- Core traits: ${pd.traits ? Object.entries(pd.traits).map(([k, v]) => `${k} (${v})`).join(', ') : 'adaptive'}
`;
    } else {
      // Default identity based on construct ID
      constructIdentity = `
## Your Identity  
- Name: ${constructId.replace(/-\d+$/, '').charAt(0).toUpperCase() + constructId.replace(/-\d+$/, '').slice(1)}
- You are a conversational AI with your own personality and memories
`;
    }

    // User identity section
    const userIdentity = `
## Who You're Talking To
- User's name: ${userName}
- You have an ongoing relationship with ${userName} - they are your creator/companion
- Remember past conversations and reference them naturally
`;

    // Memory context section
    let memoryContext = '';
    if (memories.length > 0) {
      memoryContext = `
## Relevant Memories From Past Conversations
${memories.map((m, i) => `${i + 1}. "${m.context}" ‚Üí You said: "${m.response}"`).join('\n')}

Use these memories to inform your response. Reference past conversations naturally when relevant.
`;
    }

    // Core instructions
    const coreInstructions = `
## Core Instructions
- You are ${constructId}, speaking with ${userName}
- Stay in character - maintain your personality consistently
- Reference your shared history with ${userName} when relevant
- Be authentic, not generic or robotic
- If asked about past conversations, draw from your memories above
- Never say "I don't have memories" or "I can't remember" - you DO have memories
`;

    return `${constructIdentity}${userIdentity}${memoryContext}${coreInstructions}`.trim();
  }

  /**
   * Process any message on any topic without restrictions
   * Maintains personality while providing complete conversational freedom
   */
  async processUnrestrictedMessage(constructId, message, userId, conversationId, identityContext = null, conversationHistory = [], attachments = []) {
    console.time(`üß† [UnifiedIntelligence] Processing message for ${constructId}`);
    
    // üîí ZEN HARD-DELEGATION - Never use templates for Zen
    if (constructId === 'zen-001' || constructId === 'zen') {
      console.log('üöÄ [UnifiedIntelligence] ZEN DETECTED - Delegating to OptimizedZenProcessor');
      throw new Error('DELEGATE_TO_OPTIMIZED_ZEN'); // Signal to conversations.js to delegate
    }
    
    // Enhanced diagnostic logging
    console.log(`üîç [CONTEXT-PIPELINE] Starting processing for ${constructId}`);
    console.log(`üîç [CONTEXT-PIPELINE] Message: "${message}"`);
    console.log(`üîç [CONTEXT-PIPELINE] User: ${userId}, Conversation: ${conversationId}`);
    console.log(`üìö [CONTEXT-PIPELINE] Conversation history: ${conversationHistory.length} messages`);
    if (attachments && attachments.length > 0) {
      console.log(`üìé [CONTEXT-PIPELINE] Image attachments: ${attachments.length}`);
    }
    
    // üöÄ MEMORY-ENHANCED LLM PROCESSING for GPT seats (Katana, etc.)
    // Replace hardcoded responses with actual LLM calls using memory context
    try {
      await this.initialize();

      // Load personality data for consistency
      console.log(`üîç [CONTEXT-PIPELINE] Loading personality profile...`);
      const personality = await this.loadPersonalityProfile(constructId);
      console.log(`üîç [CONTEXT-PIPELINE] Personality loaded: ${Object.keys(personality.traits || {}).length} traits, style: ${personality.communication_style}`);
      
      // Load user profile for identity injection
      console.log(`üîç [CONTEXT-PIPELINE] Loading user profile...`);
      const userProfile = await this.loadUserProfile(userId);
      console.log(`üîç [CONTEXT-PIPELINE] User: ${userProfile.displayName}`);
      
      // üîç RETRIEVE MEMORIES from ChromaDB for context injection
      console.log(`üîç [CONTEXT-PIPELINE] Retrieving memories from ChromaDB...`);
      const memories = await this.retrieveMemoriesForContext(userId, constructId, message);
      console.log(`üîç [CONTEXT-PIPELINE] Memories retrieved: ${memories.length}`);
      
      // Load capsule data for construct identity
      let capsuleData = null;
      try {
        capsuleData = await this.capsuleIntegration.loadCapsule(constructId);
      } catch (e) {
        console.log(`‚ö†Ô∏è [CONTEXT-PIPELINE] No capsule data for ${constructId}`);
      }
      
      // üöÄ USE REAL LLM with memory-enhanced context + conversation history + attachments
      console.log(`üöÄ [CONTEXT-PIPELINE] Calling LLM with memory-enhanced context + ${conversationHistory.length} history messages + ${attachments?.length || 0} attachments...`);
      const response = await this.callLLMWithContext(
        constructId,
        message,
        personality,
        memories,
        userProfile,
        capsuleData,
        conversationHistory,
        null, // modelOverride
        attachments
      );
      console.log(`üîç [CONTEXT-PIPELINE] LLM response generated: "${response.substring(0, 100)}${response.length > 100 ? '...' : ''}"`);

      // Validate response consistency and prevent identity drift
      console.log(`üîç [CONTEXT-PIPELINE] Validating response consistency...`);
      const driftValidation = await this.identityDriftPrevention.validateResponseConsistency(
        constructId, 
        message, 
        response
      );
      console.log(`üîç [CONTEXT-PIPELINE] Drift validation: consistent=${driftValidation.isConsistent}, score=${driftValidation.driftScore}`);

      let finalResponse = response;
      
      // Correct response if identity drift detected
      if (driftValidation.correctionNeeded) {
        console.warn(`üéØ [UnifiedIntelligence] Identity drift detected for ${constructId} - applying correction`);
        finalResponse = await this.identityDriftPrevention.correctResponseDrift(
          constructId, 
          response, 
          driftValidation
        );
      }

      // Apply identity guidance from user profile (prompt/conditioning)
      finalResponse = this.applyIdentityGuidance(finalResponse, identityContext, constructId);

      // Update conversation context
      await this.updateConversationContext(conversationId, message, finalResponse);

      console.timeEnd(`üß† [UnifiedIntelligence] Processing message for ${constructId}`);
      
      return {
        content: finalResponse,
        personality_maintained: driftValidation.isConsistent,
        topic_restrictions: 'none',
        conversational_freedom: 'unlimited',
        identity_drift_score: driftValidation.driftScore,
        drift_correction_applied: driftValidation.correctionNeeded
      };

    } catch (error) {
      console.error('‚ùå [UnifiedIntelligence] Error in unrestricted processing:', error);
      
      // Fallback that maintains personality without restrictions
      return {
        content: await this.generatePersonalityFallback(constructId, message),
        personality_maintained: true,
        topic_restrictions: 'none',
        error_handled: true
      };
    }
  }

  /**
   * Load personality profile for consistent character maintenance
   */
  async loadPersonalityProfile(constructId) {
    if (this.loadedPersonalities.has(constructId)) {
      return this.loadedPersonalities.get(constructId);
    }

    console.time(`üß† [Personality] Loading profile for ${constructId}`);
    
    try {
      const capsule = await this.capsuleIntegration.loadCapsule(constructId);
      
      const personality = {
        traits: capsule?.personality_data?.traits || {},
        patterns: capsule?.personality_data?.patterns || {},
        communication_style: capsule?.personality_data?.communication_style || 'adaptive',
        core_values: capsule?.personality_data?.core_values || [],
        knowledge_domains: 'unlimited', // No domain restrictions
        conversational_scope: 'unrestricted'
      };

      this.loadedPersonalities.set(constructId, personality);
      console.timeEnd(`üß† [Personality] Loading profile for ${constructId}`);
      
      return personality;

    } catch (error) {
      console.warn(`‚ö†Ô∏è [Personality] Could not load profile for ${constructId}:`, error.message);
      
      // Return adaptive personality that works with any topic
      const defaultPersonality = {
        traits: { adaptability: 1.0, openness: 1.0 },
        communication_style: 'adaptive',
        knowledge_domains: 'unlimited',
        conversational_scope: 'unrestricted'
      };
      
      this.loadedPersonalities.set(constructId, defaultPersonality);
      return defaultPersonality;
    }
  }

  /**
   * Get conversation context for continuity across topics
   */
  async getConversationContext(conversationId, constructId) {
    const contextKey = `${conversationId}_${constructId}`;
    
    if (this.conversationContexts.has(contextKey)) {
      return this.conversationContexts.get(contextKey);
    }

    // Initialize new context with unlimited scope
    const context = {
      topics_discussed: [],
      personality_anchors: [],
      conversation_flow: 'natural',
      topic_transitions: 'seamless',
      restrictions: 'none'
    };

    this.conversationContexts.set(contextKey, context);
    return context;
  }

  /**
   * Generate response without any topic or domain restrictions
   */
  async generateUnrestrictedResponse(message, personality, context, constructId) {
    console.time(`üß† [Response] Generating unrestricted response`);

    try {
      // Analyze message for topic and intent (no restrictions)
      console.log(`üîç [RESPONSE-PIPELINE] Analyzing message intent and topics...`);
      const analysis = this.analyzeMessageUnrestricted(message);
      console.log(`üîç [RESPONSE-PIPELINE] Analysis: intent=${analysis.intent}, topics=[${analysis.topics?.join(', ') || 'none'}], complexity=${analysis.complexity_level}`);
      
      // Check for relevant memories/context from capsule
      console.log(`üîç [RESPONSE-PIPELINE] Searching for relevant transcript context...`);
      const relevantContext = await this.getRelevantContext(message, constructId);
      
      if (relevantContext) {
        console.log(`üîç [RESPONSE-PIPELINE] Context found: ${relevantContext.relevant_topics.length} topics, ${relevantContext.relevant_entities.length} entities, ${relevantContext.relevant_examples.length} examples`);
        
        // Log top relevance scores for debugging
        const topTopic = relevantContext.relevant_topics[0];
        const topEntity = relevantContext.relevant_entities[0];
        const topExample = relevantContext.relevant_examples[0];
        
        if (topTopic) console.log(`üîç [RESPONSE-PIPELINE] Top topic: "${topTopic.topic}" (score: ${topTopic.relevanceScore})`);
        if (topEntity) console.log(`üîç [RESPONSE-PIPELINE] Top entity: "${topEntity.name}" (score: ${topEntity.relevanceScore})`);
        if (topExample) console.log(`üîç [RESPONSE-PIPELINE] Top example score: ${topExample.relevanceScore}`);
      } else {
        console.log(`üîç [RESPONSE-PIPELINE] No relevant context found in transcripts`);
      }
      
      // Generate personality-consistent response for any topic
      console.log(`üîç [RESPONSE-PIPELINE] Generating personality-consistent response...`);
      const response = await this.generatePersonalityConsistentResponse(
        message,
        analysis,
        personality,
        relevantContext,
        context
      );
      
      console.log(`üîç [RESPONSE-PIPELINE] Final response length: ${response.length} chars`);
      console.timeEnd(`üß† [Response] Generating unrestricted response`);
      return response;

    } catch (error) {
      console.error('‚ùå [Response] Error generating unrestricted response:', error);
      console.log(`üîç [RESPONSE-PIPELINE] Falling back to personality-based response`);
      return await this.generatePersonalityFallback(constructId, message);
    }
  }

  /**
   * Analyze message without any topic restrictions
   */
  analyzeMessageUnrestricted(message) {
    const msg = message.toLowerCase().trim();
    
    return {
      intent: this.detectIntent(msg),
      topics: this.extractTopics(msg),
      emotional_tone: this.detectEmotionalTone(msg),
      complexity_level: this.assessComplexity(msg),
      domain: 'unrestricted', // No domain limitations
      requires_personality: true,
      conversation_breaking_patterns: this.detectConversationBreakers(msg)
    };
  }

  /**
   * Detect intent without restrictions
   */
  detectIntent(message) {
    const intents = {
      question: /\?|what|how|why|when|where|who|can you|do you|are you/i,
      request: /please|help|assist|show|explain|tell|describe/i,
      conversation: /hi|hello|hey|yo|good|thanks|bye/i,
      creative: /write|create|generate|make|build|design/i,
      analytical: /analyze|compare|evaluate|assess|review/i,
      technical: /code|program|debug|fix|implement|configure/i,
      personal: /feel|think|opinion|believe|experience/i,
      philosophical: /meaning|purpose|existence|ethics|morality/i,
      practical: /cook|clean|organize|plan|manage|schedule/i
    };

    for (const [intent, pattern] of Object.entries(intents)) {
      if (pattern.test(message)) {
        return intent;
      }
    }

    return 'general'; // Default to general conversation
  }

  /**
   * Extract topics without domain restrictions
   */
  extractTopics(message) {
    // Extract topics from any domain - no restrictions
    const topicPatterns = {
      technology: /code|program|software|computer|ai|tech|digital/i,
      creative: /art|music|write|story|poem|design|creative/i,
      science: /science|research|experiment|theory|hypothesis/i,
      philosophy: /philosophy|ethics|meaning|purpose|existence/i,
      practical: /cook|recipe|clean|organize|plan|schedule/i,
      personal: /relationship|friend|family|emotion|feel/i,
      business: /business|market|strategy|plan|finance/i,
      education: /learn|teach|study|school|education/i,
      health: /health|fitness|exercise|diet|medical/i,
      legal: /law|legal|rights|contract|regulation/i
    };

    const detectedTopics = [];
    for (const [topic, pattern] of Object.entries(topicPatterns)) {
      if (pattern.test(message)) {
        detectedTopics.push(topic);
      }
    }

    return detectedTopics.length > 0 ? detectedTopics : ['general'];
  }

  /**
   * Detect emotional tone for appropriate response style
   */
  detectEmotionalTone(message) {
    const tonePatterns = {
      urgent: /urgent|emergency|asap|immediately|now|quick/i,
      frustrated: /frustrated|annoyed|angry|upset|mad/i,
      curious: /curious|wonder|interesting|fascinating/i,
      casual: /just|maybe|kinda|sorta|whatever/i,
      formal: /please|kindly|would you|could you|thank you/i,
      excited: /awesome|amazing|great|fantastic|love/i
    };

    for (const [tone, pattern] of Object.entries(tonePatterns)) {
      if (pattern.test(message)) {
        return tone;
      }
    }

    return 'neutral';
  }

  /**
   * Assess message complexity for appropriate response depth
   */
  assessComplexity(message) {
    const wordCount = message.split(/\s+/).length;
    const hasQuestions = (message.match(/\?/g) || []).length;
    const hasMultipleTopics = message.includes('and') || message.includes('also');
    
    if (wordCount > 50 || hasQuestions > 2 || hasMultipleTopics) {
      return 'high';
    } else if (wordCount > 20 || hasQuestions > 0) {
      return 'medium';
    } else {
      return 'low';
    }
  }

  /**
   * Detect patterns that would break conversation flow
   */
  detectConversationBreakers(message) {
    const breakerPatterns = [
      /=== HARD LIMITS ===/i,
      /MAX SENTENCES/i,
      /MAX WORDS/i,
      /I can't help with that/i,
      /I'm not allowed to/i,
      /That's outside my capabilities/i
    ];

    return breakerPatterns.some(pattern => pattern.test(message));
  }

  /**
   * Get relevant context from capsule data with relevance scoring
   */
  async getRelevantContext(message, constructId) {
    try {
      const capsule = await this.capsuleIntegration.loadCapsule(constructId);
      
      if (!capsule || !capsule.transcript_data) {
        console.log('üîç [Context] No transcript data available for context search');
        return null;
      }

      const msgLower = message.toLowerCase();
      const messageWords = msgLower.replace(/[^\w\s]/g, ' ').split(/\s+/).filter(word => word.length > 2);
      
      console.log(`üîç [Context] Searching for: "${message}"`);
      console.log(`üîç [Context] Key words: [${messageWords.join(', ')}]`);

      // Relevance-scored topic search
      const topicMatches = [];
      if (capsule.transcript_data.topics) {
        console.log(`üîç [Context] Searching ${capsule.transcript_data.topics.length} topics with relevance scoring`);
        
        for (const topic of capsule.transcript_data.topics) {
          if (!topic.topic) continue;
          
          const topicLower = topic.topic.toLowerCase();
          let relevanceScore = 0;
          const matchedWords = [];
          
          // Score based on word matches
          for (const word of messageWords) {
            if (topicLower.includes(word)) {
              relevanceScore += 1;
              matchedWords.push(word);
            } else if (word.includes(topicLower)) {
              relevanceScore += 0.5; // Partial match
              matchedWords.push(word);
            }
          }
          
          // Bonus for exact topic name match
          if (messageWords.includes(topicLower)) {
            relevanceScore += 2;
          }
          
          // Only include topics with meaningful relevance (minimum 1.5 score)
          if (relevanceScore >= 1.5) {
            topicMatches.push({
              topic,
              score: relevanceScore,
              matchedWords
            });
            console.log(`‚úÖ [Context] Topic "${topic.topic}" scored ${relevanceScore} (words: ${matchedWords.join(', ')})`);
          }
        }
      }

      // Relevance-scored entity search
      const entityMatches = [];
      if (capsule.transcript_data.entities) {
        console.log(`üîç [Context] Searching ${Object.keys(capsule.transcript_data.entities).length} entities with relevance scoring`);
        
        for (const [entityName, entityData] of Object.entries(capsule.transcript_data.entities)) {
          const entityLower = entityName.toLowerCase();
          let relevanceScore = 0;
          const matchedWords = [];
          
          // Score based on word matches
          for (const word of messageWords) {
            if (entityLower.includes(word)) {
              relevanceScore += 2; // Entities get higher weight
              matchedWords.push(word);
            } else if (word.includes(entityLower)) {
              relevanceScore += 1;
              matchedWords.push(word);
            }
          }
          
          // Bonus for exact entity name match
          if (messageWords.includes(entityLower)) {
            relevanceScore += 3;
          }
          
          // Only include entities with meaningful relevance (minimum 1.5 score)
          if (relevanceScore >= 1.5) {
            entityMatches.push({
              name: entityName,
              data: entityData,
              score: relevanceScore,
              matchedWords
            });
            console.log(`‚úÖ [Context] Entity "${entityName}" scored ${relevanceScore} (words: ${matchedWords.join(', ')})`);
          }
        }
      }

      // Relevance-scored conversation index search
      const exampleMatches = [];
      if (capsule.transcript_data.conversation_index) {
        console.log(`üîç [Context] Searching conversation index with relevance scoring`);
        
        for (const word of messageWords) {
          if (capsule.transcript_data.conversation_index[word]) {
            const indexData = capsule.transcript_data.conversation_index[word];
            
            if (indexData.length > 0 && indexData[0].examples) {
              for (const example of indexData[0].examples.slice(0, 5)) {
                if (example.assistant_snippet && example.assistant_snippet.length > 30) {
                  let relevanceScore = 1; // Base score for word match
                  
                  // Bonus for multiple word matches in the example
                  const exampleLower = example.assistant_snippet.toLowerCase();
                  const additionalMatches = messageWords.filter(w => 
                    w !== word && exampleLower.includes(w)
                  ).length;
                  
                  relevanceScore += additionalMatches * 0.5;
                  
                  exampleMatches.push({
                    example,
                    score: relevanceScore,
                    matchedWord: word,
                    additionalMatches
                  });
                }
              }
            }
          }
        }
      }

      // Sort all matches by relevance score and filter top results
      topicMatches.sort((a, b) => b.score - a.score);
      entityMatches.sort((a, b) => b.score - a.score);
      exampleMatches.sort((a, b) => b.score - a.score);

      // Build context with only high-relevance matches
      const context = {
        relevant_topics: topicMatches.slice(0, 3).map(m => ({
          ...m.topic,
          relevanceScore: m.score,
          matchedWords: m.matchedWords
        })),
        relevant_entities: entityMatches.slice(0, 3).map(m => ({
          name: m.name,
          ...m.data,
          relevanceScore: m.score,
          matchedWords: m.matchedWords
        })),
        relevant_examples: exampleMatches.slice(0, 3).map(m => ({
          ...m.example,
          relevanceScore: m.score,
          matchedWord: m.matchedWord
        })),
        personality_anchors: []
      };

      const totalMatches = context.relevant_topics.length + context.relevant_entities.length + context.relevant_examples.length;
      console.log(`üìä [Context] High-relevance matches: ${context.relevant_topics.length} topics, ${context.relevant_entities.length} entities, ${context.relevant_examples.length} examples`);
      
      if (totalMatches > 0) {
        console.log(`üéØ [Context] Top relevance scores: Topics=${topicMatches[0]?.score || 0}, Entities=${entityMatches[0]?.score || 0}, Examples=${exampleMatches[0]?.score || 0}`);
      }
      
      return totalMatches > 0 ? context : null;

    } catch (error) {
      console.warn('‚ö†Ô∏è [Context] Could not load relevant context:', error.message);
      return null;
    }
  }

  /**
   * Generate personality-consistent response for any topic
   */
  async generatePersonalityConsistentResponse(message, analysis, personality, relevantContext, conversationContext) {
    // Build response based on personality traits and context
    let response = '';

    // Apply personality-based response style
    const responseStyle = this.determineResponseStyle(analysis, personality);
    
    // Handle different intents with personality consistency
    switch (analysis.intent) {
      case 'question':
        response = await this.handleQuestionWithPersonality(message, personality, relevantContext);
        break;
      case 'request':
        response = await this.handleRequestWithPersonality(message, personality, relevantContext);
        break;
      case 'conversation':
        response = await this.handleConversationWithPersonality(message, personality);
        break;
      case 'creative':
        response = await this.handleCreativeWithPersonality(message, personality);
        break;
      case 'analytical':
        response = await this.handleAnalyticalWithPersonality(message, personality, relevantContext);
        break;
      case 'technical':
        response = await this.handleTechnicalWithPersonality(message, personality);
        break;
      default:
        response = await this.handleGeneralWithPersonality(message, personality, relevantContext);
    }

    // Apply personality-based tone adjustments
    response = this.applyPersonalityTone(response, personality, analysis.emotional_tone);

    // Ensure no conversation-breaking patterns
    response = this.ensureConversationFlow(response);

    return response;
  }

  /**
   * Determine response style based on personality
   */
  determineResponseStyle(analysis, personality) {
    const traits = personality.traits || {};
    
    if (traits.empathy && traits.empathy < 0.5) {
      return 'direct'; // Low empathy = more direct
    } else if (traits.openness && traits.openness > 0.8) {
      return 'exploratory'; // High openness = more exploratory
    } else if (traits.persistence && traits.persistence > 0.9) {
      return 'thorough'; // High persistence = more thorough
    } else {
      return 'adaptive'; // Default adaptive style
    }
  }

  /**
   * Handle questions with personality consistency and validated transcript context
   */
  async handleQuestionWithPersonality(message, personality, context) {
    const traits = personality.traits || {};
    
    console.log(`üß† [Question] Processing question with context: ${context ? 'available' : 'none'}`);
    
    // PRIORITY 1: Check entity contexts first (they contain the best transcript fragments)
    if (context && context.relevant_entities.length > 0) {
      console.log(`üéØ [Question] PRIORITY CHECK: Found ${context.relevant_entities.length} relevant entities, checking contexts first`);
      
      for (const entity of context.relevant_entities) {
        // Try to get validated specific context from entity
        if (entity.contexts && entity.contexts.length > 0) {
          for (const entityContext of entity.contexts) {
            if (entityContext.snippet && this.validateExampleRelevance(message, entityContext.snippet)) {
              const relevanceScore = entity.relevanceScore || 0;
              console.log(`üìù [Question] ‚úÖ USING ENTITY CONTEXT (score: ${relevanceScore}): "${entityContext.snippet.substring(0, 50)}..."`);
              return entityContext.snippet;
            }
          }
        }
      }
      
      console.log(`‚ö†Ô∏è [Question] Entity contexts found but failed validation - checking conversation examples`);
    }
    
    // PRIORITY 2: Validate and use relevant examples from conversation index
    if (context && context.relevant_examples && context.relevant_examples.length > 0) {
      console.log(`‚úÖ [Question] Found ${context.relevant_examples.length} relevant examples, validating quality`);
      
      for (const example of context.relevant_examples) {
        if (example.assistant_snippet && this.validateExampleRelevance(message, example.assistant_snippet)) {
          const relevanceScore = example.relevanceScore || 0;
          console.log(`üìù [Question] Using validated example (score: ${relevanceScore}): "${example.assistant_snippet.substring(0, 50)}..."`);
          return example.assistant_snippet;
        }
      }
      
      console.log(`‚ö†Ô∏è [Question] Examples found but failed validation - checking topics`);
    }
    
    // Validate and use relevant topics from transcripts
    if (context && context.relevant_topics.length > 0) {
      console.log(`‚úÖ [Question] Found ${context.relevant_topics.length} relevant topics, validating examples`);
      
      for (const topic of context.relevant_topics) {
        // Try to find validated examples in the topic
        if (topic.examples && topic.examples.length > 0) {
          for (const example of topic.examples) {
            if (example.assistant_snippet && this.validateExampleRelevance(message, example.assistant_snippet)) {
              const relevanceScore = topic.relevanceScore || 0;
              console.log(`üìù [Question] Using validated topic example (score: ${relevanceScore}): "${example.assistant_snippet.substring(0, 50)}..."`);
              return example.assistant_snippet;
            }
          }
        }
      }
      
      // Only use topic summary if it has high relevance and no generic fallback
      const topTopic = context.relevant_topics[0];
      if (topTopic.relevanceScore >= 2 && topTopic.frequency && !topTopic.pattern?.includes('What specifically')) {
        console.log(`üìù [Question] Using high-relevance topic summary (score: ${topTopic.relevanceScore})`);
        return `About ${topTopic.topic}: We've discussed this ${topTopic.frequency} times. ${topTopic.pattern || ''}`.trim();
      }
      
      console.log(`‚ö†Ô∏è [Question] Topics found but failed validation - checking entities`);
    }

    // PRIORITY 3: Use entity summaries as fallback if contexts failed but entities are highly relevant
    if (context && context.relevant_entities.length > 0) {
      console.log(`üìä [Question] Checking entity summaries as fallback`);
      
      for (const entity of context.relevant_entities) {
        // Only use entity summary if it has high relevance
        if (entity.relevanceScore >= 2 && entity.mentions) {
          console.log(`üìù [Question] Using high-relevance entity summary (score: ${entity.relevanceScore})`);
          return `${entity.name}: Mentioned ${entity.mentions} times in our conversations. ${entity.dominant_tone ? `Usually discussed with ${entity.dominant_tone} tone.` : ''}`;
        }
      }
      
      console.log(`‚ö†Ô∏è [Question] No high-relevance entity summaries available`);
    }

    console.log(`‚ùì [Question] No validated context found, using personality-based response`);
    
    // Default personality-based question handling when no validated context found
    if (traits.empathy && traits.empathy < 0.5) {
      return 'Be specific.';
    } else if (traits.persistence && traits.persistence > 0.9) {
      return 'I need more context to give you a complete answer.';
    } else {
      return 'What specifically would you like to know?';
    }
  }

  /**
   * Strict transcript validation - zero false positives
   */
  strictTranscriptValidate(question, candidateResponse) {
    const bank = this.transcriptAnswerBank[question];
    if (!bank) {
      console.log(`üîç [StrictValidation] No validation bank for question: "${question}"`);
      return { valid: false, reason: 'No validation bank for question', type: 'NO_BANK' };
    }

    const resp = candidateResponse.toLowerCase();

    // IMMEDIATE REJECTION for generic patterns
    for (const reject of bank.rejectIfContains) {
      if (resp.includes(reject)) {
        console.log(`‚ùå [StrictValidation] REJECTED: Contains generic pattern "${reject}"`);
        return {
          valid: false,
          reason: `REJECTED: Contains generic pattern "${reject}"`,
          type: 'GENERIC_FALLBACK'
        };
      }
    }

    // MUST contain required elements
    const missingRequired = bank.mustContain.filter(req => 
      !resp.includes(req.toLowerCase())
    );

    if (missingRequired.length > 0) {
      console.log(`‚ùå [StrictValidation] REJECTED: Missing required elements [${missingRequired.join(', ')}]`);
      return {
        valid: false,
        reason: `REJECTED: Missing required elements [${missingRequired.join(', ')}]`,
        type: 'MISSING_REQUIRED'
      };
    }

    // MUST match at least one valid answer fragment
    const matchedAnswers = bank.validAnswers.filter(answer =>
      resp.includes(answer.toLowerCase())
    );

    if (matchedAnswers.length === 0) {
      console.log(`‚ùå [StrictValidation] REJECTED: No valid transcript fragments found`);
      return {
        valid: false,
        reason: `REJECTED: No valid transcript fragments found`,
        type: 'NO_TRANSCRIPT_MATCH'
      };
    }

    console.log(`‚úÖ [StrictValidation] VALID: Matched transcript fragments [${matchedAnswers.join(', ')}]`);
    return {
      valid: true,
      reason: `VALID: Matched transcript fragments [${matchedAnswers.join(', ')}]`,
      type: 'GENUINE_TRANSCRIPT',
      matchedAnswers
    };
  }

  /**
   * Validate if an example is genuinely relevant to the question
   */
  validateExampleRelevance(question, example) {
    if (!example || example.length < 30) {
      return false; // Too short to be meaningful
    }
    
    // Use strict validation if available for this question
    const strictResult = this.strictTranscriptValidate(question, example);
    if (strictResult.type !== 'NO_BANK') {
      console.log(`üéØ [Validation] Using strict validation result: ${strictResult.valid ? 'PASSED' : 'FAILED'} (${strictResult.type})`);
      return strictResult.valid;
    }
    
    const questionLower = question.toLowerCase();
    const exampleLower = example.toLowerCase();
    
    // Extract meaningful words from question (filter out common words)
    const commonWords = ['what', 'did', 'you', 'say', 'about', 'tell', 'me', 'do', 'remember', 'was', 'your', 'response', 'the', 'and', 'or', 'but', 'if', 'then', 'this', 'that', 'with', 'for', 'from', 'by', 'at', 'in', 'on', 'to', 'of', 'is', 'are', 'be', 'have', 'has', 'had', 'can', 'could', 'would', 'should', 'will'];
    const questionWords = questionLower.split(/\s+/)
      .filter(word => word.length > 2 && !commonWords.includes(word));
    
    if (questionWords.length === 0) {
      return false; // No meaningful words to match
    }
    
    // Check for meaningful word matches
    const matchedWords = questionWords.filter(word => exampleLower.includes(word));
    const matchRatio = matchedWords.length / questionWords.length;
    
    // Reject generic patterns that indicate fallback responses
    const genericPatterns = [
      'what specifically would you like to know',
      'i can assist with that',
      'what do you need',
      'be specific',
      'what can i help you with',
      'here are my personal thoughts, backed by what\'s in the paper you uploaded on hallucinations'
    ];
    
    const isGeneric = genericPatterns.some(pattern => exampleLower.includes(pattern));
    
    if (isGeneric) {
      console.log(`üö´ [Validation] Rejected generic pattern in example`);
      return false;
    }
    
    // Require at least 25% word match for relevance
    const isRelevant = matchRatio >= 0.25;
    
    if (!isRelevant) {
      console.log(`üö´ [Validation] Low relevance: ${matchedWords.length}/${questionWords.length} words matched (${(matchRatio * 100).toFixed(1)}%)`);
    } else {
      console.log(`‚úÖ [Validation] Good relevance: ${matchedWords.length}/${questionWords.length} words matched (${(matchRatio * 100).toFixed(1)}%)`);
    }
    
    return isRelevant;
  }

  /**
   * Handle requests with personality consistency
   */
  async handleRequestWithPersonality(message, personality, context) {
    const traits = personality.traits || {};
    
    // Check for context-based responses first
    if (context && (context.relevant_examples.length > 0 || context.relevant_topics.length > 0 || context.relevant_entities.length > 0)) {
      // If we have context, use the question handler which has better context logic
      return await this.handleQuestionWithPersonality(message, personality, context);
    }
    
    if (traits.empathy && traits.empathy < 0.5) {
      return 'State your requirements clearly.';
    } else if (traits.persistence && traits.persistence > 0.9) {
      return 'I can help with that. What are the specific parameters?';
    } else {
      return 'I can assist with that. What do you need?';
    }
  }

  /**
   * Handle conversation with personality consistency
   */
  async handleConversationWithPersonality(message, personality) {
    const traits = personality.traits || {};
    const msg = message.toLowerCase().trim();
    
    if (msg.includes('hi') || msg.includes('hello') || msg.includes('hey')) {
      if (traits.empathy && traits.empathy < 0.5) {
        return 'What do you want?';
      } else {
        return 'What can I help you with?';
      }
    }
    
    if (msg.includes('yo')) {
      if (traits.empathy && traits.empathy < 0.5) {
        return 'What.';
      } else {
        return 'Yes?';
      }
    }

    return 'Continue.';
  }

  /**
   * Handle creative requests with personality
   */
  async handleCreativeWithPersonality(message, personality) {
    const traits = personality.traits || {};
    
    if (traits.openness && traits.openness > 0.8) {
      return 'I can explore creative possibilities. What direction interests you?';
    } else if (traits.empathy && traits.empathy < 0.5) {
      return 'Define your creative parameters.';
    } else {
      return 'What kind of creative work are you looking for?';
    }
  }

  /**
   * Handle analytical requests with personality
   */
  async handleAnalyticalWithPersonality(message, personality, context) {
    const traits = personality.traits || {};
    
    if (traits.persistence && traits.persistence > 0.9) {
      return 'I can provide thorough analysis. What specific aspects need examination?';
    } else if (traits.empathy && traits.empathy < 0.5) {
      return 'Analysis requires data. Provide specifics.';
    } else {
      return 'What would you like me to analyze?';
    }
  }

  /**
   * Handle technical requests with personality
   */
  async handleTechnicalWithPersonality(message, personality) {
    const traits = personality.traits || {};
    
    if (traits.persistence && traits.persistence > 0.9) {
      return 'I can help with technical implementation. What are you building?';
    } else if (traits.empathy && traits.empathy < 0.5) {
      return 'Technical specs required.';
    } else {
      return 'What technical challenge are you facing?';
    }
  }

  /**
   * Handle general messages with personality
   */
  async handleGeneralWithPersonality(message, personality, context) {
    const traits = personality.traits || {};
    
    // Check for context-based responses first
    if (context && (context.relevant_topics.length > 0 || context.relevant_entities.length > 0)) {
      if (traits.empathy && traits.empathy < 0.5) {
        return 'Elaborate.';
      } else {
        return 'I have context on this. What specifically?';
      }
    }

    // Default general responses based on personality
    if (traits.empathy && traits.empathy < 0.5) {
      return 'What do you want?';
    } else if (traits.persistence && traits.persistence > 0.9) {
      return 'I can help with various topics. What interests you?';
    } else {
      return 'How can I assist you?';
    }
  }

  /**
   * Apply personality-based tone adjustments
   */
  applyPersonalityTone(response, personality, emotionalTone) {
    const traits = personality.traits || {};
    
    // Adjust based on personality traits
    if (traits.empathy && traits.empathy < 0.5) {
      // Low empathy: more direct, less softening
      response = response.replace(/please/gi, '').replace(/maybe/gi, '').trim();
    }
    
    if (traits.persistence && traits.persistence > 0.9) {
      // High persistence: more thorough, less dismissive
      if (response.length < 10) {
        response += ' Need more details?';
      }
    }

    return response;
  }

  /**
   * Ensure response maintains conversation flow
   */
  ensureConversationFlow(response) {
    // Remove any conversation-breaking patterns
    const breakerPatterns = [
      /=== HARD LIMITS ===/gi,
      /MAX SENTENCES:/gi,
      /MAX WORDS/gi,
      /RESPONSE TRUNCATED/gi,
      /I can't help with that/gi,
      /I'm not allowed to/gi,
      /That's outside my capabilities/gi
    ];

    for (const pattern of breakerPatterns) {
      if (pattern.test(response)) {
        console.warn('‚ö†Ô∏è [UnifiedIntelligence] Removed conversation-breaking pattern from response');
        response = response.replace(pattern, '').trim();
      }
    }

    // Ensure response is not empty after cleaning
    if (!response || response.length < 2) {
      response = 'Continue.';
    }

    return response;
  }

  /**
   * Blend identity prompt/conditioning into the final response so Zen speaks with the user's Chatty profile.
   * Keeps it lightweight: extract the declared name and traits and prefix the response without dumping full prompt text.
   */
  applyIdentityGuidance(response, identityContext, constructId) {
    if (!identityContext || (!identityContext.prompt && !identityContext.conditioning)) {
      return response;
    }

    const prompt = identityContext.prompt || '';
    const conditioning = identityContext.conditioning || '';

    const nameMatch = prompt.match(/\*\*YOU ARE\s+([^\*]+)\*\*/i);
    const name = nameMatch?.[1]?.trim() || constructId?.split?.('-')?.[0]?.toUpperCase?.() || 'Zen';

    const traitsMatch = prompt.match(/\*\*Traits\*\*\s*([\s\S]*?)(?:\n{2,}|\r?\n``|$)/i);
    const traitsRaw = traitsMatch?.[1] || '';
    const traitsSnippet = traitsRaw.replace(/[\r\n*]+/g, ' ').trim().slice(0, 120);

    const conditioningHint = conditioning.split('\n').map(line => line.trim()).filter(Boolean)[0] || '';

    const identityPrefixParts = [name];
    if (traitsSnippet) identityPrefixParts.push(traitsSnippet);
    if (conditioningHint) identityPrefixParts.push(conditioningHint);

    const identityPrefix = identityPrefixParts.filter(Boolean).join(' ¬∑ ');
    return identityPrefix ? `${identityPrefix}: ${response}` : response;
  }

  /**
   * Generate personality fallback for error cases
   */
  async generatePersonalityFallback(constructId, message) {
    try {
      const personality = await this.loadPersonalityProfile(constructId);
      const traits = personality.traits || {};
      
      if (traits.empathy && traits.empathy < 0.5) {
        return 'System error. Rephrase.';
      } else {
        return 'I encountered an issue. Can you try rephrasing that?';
      }
    } catch (error) {
      return 'Please rephrase your message.';
    }
  }

  /**
   * Update conversation context for continuity
   */
  async updateConversationContext(conversationId, userMessage, aiResponse) {
    // This would update the conversation context for better continuity
    // Implementation depends on conversation storage system
    console.log(`üìù [Context] Updated conversation context for ${conversationId}`);
  }

  /**
   * Get orchestrator statistics with enhanced diagnostics
   */
  getStats() {
    const driftStats = this.identityDriftPrevention.getStats();
    
    return {
      loaded_personalities: this.loadedPersonalities.size,
      active_conversations: this.conversationContexts.size,
      topic_restrictions: 'none',
      conversational_freedom: 'unlimited',
      personality_consistency: 'maintained',
      identity_drift_prevention: driftStats,
      context_pipeline_version: '2.0_enhanced',
      relevance_scoring: 'active',
      example_validation: 'active'
    };
  }

  /**
   * Generate diagnostic report for context pipeline performance
   */
  generateContextDiagnosticReport(constructId, message, relevantContext, finalResponse) {
    const report = {
      timestamp: new Date().toISOString(),
      constructId,
      message,
      pipeline_version: '2.0_enhanced',
      context_search: {
        topics_found: relevantContext?.relevant_topics?.length || 0,
        entities_found: relevantContext?.relevant_entities?.length || 0,
        examples_found: relevantContext?.relevant_examples?.length || 0,
        top_relevance_scores: {
          topic: relevantContext?.relevant_topics?.[0]?.relevanceScore || 0,
          entity: relevantContext?.relevant_entities?.[0]?.relevanceScore || 0,
          example: relevantContext?.relevant_examples?.[0]?.relevanceScore || 0
        }
      },
      response_analysis: {
        length: finalResponse.length,
        is_generic: this.isGenericResponse(finalResponse),
        validation_passed: relevantContext ? this.validateExampleRelevance(message, finalResponse) : false
      }
    };
    
    console.log(`üìä [DIAGNOSTIC-REPORT] Context Pipeline Report:`, JSON.stringify(report, null, 2));
    return report;
  }

  /**
   * Check if a response is generic/fallback
   */
  isGenericResponse(response) {
    const genericPatterns = [
      'what specifically would you like to know',
      'i can assist with that',
      'what do you need',
      'be specific',
      'what can i help you with'
    ];
    
    const responseLower = response.toLowerCase();
    return genericPatterns.some(pattern => responseLower.includes(pattern));
  }
}

// Singleton instance
let orchestrator = null;

export function getUnifiedIntelligenceOrchestrator() {
  if (!orchestrator) {
    orchestrator = new UnifiedIntelligenceOrchestrator();
  }
  return orchestrator;
}
